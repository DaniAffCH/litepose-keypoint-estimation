{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Litepose \n",
    "[Litepose][1] proposes an efficient way to perform pose estimation, providing a low computationl cost, scale invariant and reliable architecture. It follows a bottom-up approach, namely it uses just one network to do both keypoints estimation and grouping. In this implementation I have also relied on two other papers (also cited by Litepose), one is [HigherHRNet][2] that proposes the main architecture and the other is [Associative Embedding][3] that introduces a way to assign identity-free keypoints to the person they belong to.\n",
    "\n",
    "Litepose modifies the HigherHRNet architecture going from a multi-branch to a single-branch one by gradual shrinking, with the purpose of speeding up the inference, making it run on low computational power devices as well.\n",
    "\n",
    "The architecture uses a MobileNet backbone with **Large Kernel Convolutions** that have shown great results empirically. The backbone output is passed to multiple deconvolutional blocks implementing the main feature of the Litepose Paper that is **Fusion Deconv Head**. This allows to obtain scale aware results by merging backbone intermediate features and refined features, in this way the network can exploit high resolution features, that help to catch close joints, without involving a multi-branch architecture. \n",
    "\n",
    "Let $t$ be the number of convolutional blocks and $n$ be the number of the current deconvolutional block, the features fusion is implemented by summing the features of deconvolutional block in position $n$ with the features of backbone block in position $t-n-1$, refined by an additional convolutional layer. Eventually the merged features are passed to a final block for each deconvolutional layer that produces the output. The results of the network are provided in several scales, one for each deconvolutional layer. Hence the output is a $(n,j,s_i,s_i)$ tensor where $n$ is the number of scales (i.e. deconv blocks), $j$ is the number of joints that we want to detect, $s_i$ for $i\\in{1,2,...,n}$ is the size of the current scale. The image ... clarifies the network structure.\n",
    "\n",
    "[1]:https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.pdf\n",
    "[2]:https://arxiv.org/pdf/1908.10357.pdf\n",
    "[3]:https://papers.nips.cc/paper/2017/file/8edd72158ccd2a879f79cb2538568fdc-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lp_coco_utils.lp_getDataset import getDatasetProcessed\n",
    "from lp_training.lp_trainer import train\n",
    "from lp_training.lp_loss import computeLoss\n",
    "from lp_model.lp_litepose import LitePose\n",
    "import lp_config.lp_common_config as cc\n",
    "import torch\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, normalizeImage, drawSkeleton\n",
    "from lp_testing.lp_evaluation import computeOKS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has to be seen only as an entry that calls wrapper functions, the implentation of those functions can be found in the subdirectories of the repository.   \n",
    "Every hyperparameter can be edited in `src/lp_config`.  \n",
    "`lp_common_config.py` contains the general configurations about the dataset loading, training and inference. On the other hand `lp_model_config.py` contrains the parameters that encode the model structure. The current model configs are taken from the Neural Architecture Search performed by the paper authors. I used the small size network due to the computational power available, however better results can be achieved simply by scaling the network size (Good parameters combinations are provided by the paper authors)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken by the [official paper repository](https://github.com/mit-han-lab/litepose):\n",
    "- classes `CocoDataset` and `CocoKeypoints` are partially taken, I added fiftyone support that makes the dataset setup easier and I removed unnecessary code.\n",
    "- I took the code inside `lp_generators.py` and `lp_transforms.py` as well, since they were a `CocoKeypoints` dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The dataset is downloaded by using fiftyone APIs and keypoint heatmaps are created for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.78it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #1 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.08047071336954832\n",
      "heatmap Loss = 0.07520170802809298\n",
      "tag Loss = 0.005269005094654858\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.016819940937682985\n",
      "heatmap Loss = 0.012100410318933427\n",
      "tag Loss = 0.004719530618283898\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:35<00:00,  6.95it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #2 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.01762638370320201\n",
      "heatmap Loss = 0.012879698220640421\n",
      "tag Loss = 0.004746685437858104\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013628414099104702\n",
      "heatmap Loss = 0.008918515951838344\n",
      "tag Loss = 0.004709898107685149\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.88it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 20.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #3 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.014641476087272167\n",
      "heatmap Loss = 0.009914935329928994\n",
      "tag Loss = 0.004726540789939463\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013281734415329993\n",
      "heatmap Loss = 0.008567944450303911\n",
      "tag Loss = 0.004713789953384549\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.78it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #4 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.014037863615900278\n",
      "heatmap Loss = 0.009304489215835928\n",
      "tag Loss = 0.004733374439179898\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013867149045690894\n",
      "heatmap Loss = 0.009160315503831952\n",
      "tag Loss = 0.004706833506934345\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.86it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #5 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013796656161546707\n",
      "heatmap Loss = 0.009107654850929976\n",
      "tag Loss = 0.004689001296646893\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.015042394181713463\n",
      "heatmap Loss = 0.009902948658913373\n",
      "tag Loss = 0.0051394454846158625\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.78it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #6 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013556378792971373\n",
      "heatmap Loss = 0.008887629497796297\n",
      "tag Loss = 0.004668749294243753\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013232948506250978\n",
      "heatmap Loss = 0.008584347394295037\n",
      "tag Loss = 0.004648601124528796\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:37<00:00,  6.66it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #7 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013300016470253468\n",
      "heatmap Loss = 0.008642715716734528\n",
      "tag Loss = 0.0046573007432743905\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.055786728955805304\n",
      "heatmap Loss = 0.051002869371324776\n",
      "tag Loss = 0.004783859477378428\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.84it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #8 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013222670879215002\n",
      "heatmap Loss = 0.008575820753350854\n",
      "tag Loss = 0.004646850080229342\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012928037642501295\n",
      "heatmap Loss = 0.008297235233709217\n",
      "tag Loss = 0.0046308024278841915\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.81it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #9 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.01302877901494503\n",
      "heatmap Loss = 0.008380192602053284\n",
      "tag Loss = 0.004648586425930261\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.01295717848651111\n",
      "heatmap Loss = 0.008306454771198332\n",
      "tag Loss = 0.00465072370460257\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.84it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013029399439692496\n",
      "heatmap Loss = 0.00838365208543837\n",
      "tag Loss = 0.004645747371017933\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012876895803026854\n",
      "heatmap Loss = 0.0082467020326294\n",
      "tag Loss = 0.004630193808116019\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.85it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #11 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.01295751177892089\n",
      "heatmap Loss = 0.008302106786519289\n",
      "tag Loss = 0.004655405006371439\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012824951919727028\n",
      "heatmap Loss = 0.008177054868079722\n",
      "tag Loss = 0.004647897041868418\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.81it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #12 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012882953956723214\n",
      "heatmap Loss = 0.00824509616754949\n",
      "tag Loss = 0.004637857780791819\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012836325895041228\n",
      "heatmap Loss = 0.00820368056325242\n",
      "tag Loss = 0.004632645340403542\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:37<00:00,  6.65it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #13 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.01296816450357437\n",
      "heatmap Loss = 0.008315359145402908\n",
      "tag Loss = 0.004652805358171463\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.01282859725691378\n",
      "heatmap Loss = 0.008176085074432194\n",
      "tag Loss = 0.00465251217642799\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:39<00:00,  6.38it/s]\n",
      "100%|██████████| 500/500 [00:26<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #14 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012867116160690785\n",
      "heatmap Loss = 0.008221789864823222\n",
      "tag Loss = 0.004645326280966401\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012760887102223933\n",
      "heatmap Loss = 0.008120832859538496\n",
      "tag Loss = 0.0046400542431510984\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:37<00:00,  6.73it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #15 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012857821855694056\n",
      "heatmap Loss = 0.008207674564793706\n",
      "tag Loss = 0.004650147279724479\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012875987044535577\n",
      "heatmap Loss = 0.008235850444994867\n",
      "tag Loss = 0.004640136564616114\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:38<00:00,  6.55it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #16 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012847450278699398\n",
      "heatmap Loss = 0.008199847046285867\n",
      "tag Loss = 0.004647603264078498\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012733603549189865\n",
      "heatmap Loss = 0.008076060827821493\n",
      "tag Loss = 0.004657542700413615\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.79it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #17 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012751270856708288\n",
      "heatmap Loss = 0.00810851182602346\n",
      "tag Loss = 0.004642759037204087\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012750382878817619\n",
      "heatmap Loss = 0.008107863499782979\n",
      "tag Loss = 0.004642519370652735\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.85it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #18 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012810359228402375\n",
      "heatmap Loss = 0.008172775665298105\n",
      "tag Loss = 0.004637583567760885\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013524260600097477\n",
      "heatmap Loss = 0.008881290347315371\n",
      "tag Loss = 0.004642970251152292\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.84it/s]\n",
      "100%|██████████| 500/500 [00:27<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #19 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013021481834352016\n",
      "heatmap Loss = 0.008378675501793623\n",
      "tag Loss = 0.004642806359566748\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013007370192557573\n",
      "heatmap Loss = 0.008359879932366312\n",
      "tag Loss = 0.004647490238305181\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:38<00:00,  6.44it/s]\n",
      "100%|██████████| 500/500 [00:26<00:00, 18.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #20 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.01305600407719612\n",
      "heatmap Loss = 0.00841228255815804\n",
      "tag Loss = 0.004643721512518823\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012982219656929373\n",
      "heatmap Loss = 0.008344521477818488\n",
      "tag Loss = 0.004637698173988611\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.83it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #21 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.013030008919537067\n",
      "heatmap Loss = 0.008384572545066476\n",
      "tag Loss = 0.004645436380989849\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.013055928810499608\n",
      "heatmap Loss = 0.008404898783192038\n",
      "tag Loss = 0.0046510300131049\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:37<00:00,  6.68it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #22 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012890338525176048\n",
      "heatmap Loss = 0.008252503329887986\n",
      "tag Loss = 0.004637835164554417\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.01293287575431168\n",
      "heatmap Loss = 0.008272846695035696\n",
      "tag Loss = 0.004660029043443501\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.76it/s]\n",
      "100%|██████████| 500/500 [00:25<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #23 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012886956293135882\n",
      "heatmap Loss = 0.00822942927479744\n",
      "tag Loss = 0.0046575270304456354\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012873668960295617\n",
      "heatmap Loss = 0.008236169890500605\n",
      "tag Loss = 0.004637499056756497\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:37<00:00,  6.59it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #24 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012826781220734119\n",
      "heatmap Loss = 0.008184250904247166\n",
      "tag Loss = 0.004642530271783471\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012793014236725866\n",
      "heatmap Loss = 0.008143021154683083\n",
      "tag Loss = 0.004649993083439767\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:36<00:00,  6.83it/s]\n",
      "100%|██████████| 500/500 [00:24<00:00, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #25 \n",
      "\n",
      "TRAINING LOSS:\n",
      "total Loss = 0.012838764283806085\n",
      "heatmap Loss = 0.008203745471313596\n",
      "tag Loss = 0.004635018786415457\n",
      "\n",
      "VALIDATION LOSS:\n",
      "total Loss = 0.012763793285936118\n",
      "heatmap Loss = 0.00813878972362727\n",
      "tag Loss = 0.004625003540422767\n",
      "\n",
      "\n",
      "\n",
      "end training, exec time: 1549.6994819641113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(cc.config[\"batch_size\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Unfotunately OpenCV method `imshow()` has a well known bug with python notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(\"lp_trained_models/mytag\"))\n",
    "\n",
    "ds = getDatasetProcessed(\"validation\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "row = next(iter(data_loader))\n",
    "images = row[0].to(cc.config[\"device\"])\n",
    "#img_size = 256\n",
    "#images = F.interpolate(images, size = (img_size, img_size))\n",
    "gthm = row[1]\n",
    "output, keypoints = inference(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = assocEmbedding(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jointsHeatmap = output[1][2][:cc.config[\"num_joints\"]]\n",
    "\n",
    "img, finalHm, superimposed = drawHeatmap(images[2], jointsHeatmap)\n",
    "img, gtfinalHm, gtsuperimposed = drawHeatmap(images[2], gthm[1][2])\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Final heatmap\", finalHm)\n",
    "cv2.imshow(\"Superimposed\", superimposed)\n",
    "\n",
    "cv2.imshow(\"Ground Truth heatmap\", gtfinalHm)\n",
    "cv2.imshow(\"Ground Truth Superimposed\", gtsuperimposed)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 128, 128])\n",
      "torch.Size([28, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "import lp_utils.lp_image_processing as ip\n",
    "import numpy as np\n",
    "\n",
    "img = images[1]\n",
    "\n",
    "tj = output[1][1]\n",
    "\n",
    "for t in range(14,28):\n",
    "    tagJoints = tj[t]\n",
    "    scaled = ip.scaleImage(tagJoints.unsqueeze(0), img.shape[1]).cpu().numpy()\n",
    "    scaled = scaled[0]\n",
    "    scaled = ip.normalizeImage(scaled)\n",
    "    finalHm = cv2.applyColorMap(np.uint8(scaled), cv2.COLORMAP_JET)\n",
    "    cv2.imshow(str(t), finalHm)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "#img = normalizeImage(img)\n",
    "#img = np.uint8(img)\n",
    "#heatmaps = ip.scaleImage(tagJoints, img.shape[1]).cpu().numpy()\n",
    "\n",
    "#finalHm = ip.mergeMultipleHeatmaps(heatmaps)\n",
    "#finalHm = normalizeImage(finalHm)\n",
    "#finalHm = cv2.applyColorMap(np.uint8(finalHm), cv2.COLORMAP_JET)\n",
    "\n",
    "#cv2.imshow(\"Final heatmap\", finalHm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tagJoints = output[1][2][cc.config[\"num_joints\"]:]\n",
    "\n",
    "print(tagJoints[0].max())\n",
    "\n",
    "img, finalHm, superimposed = drawHeatmap(images[2], tagJoints)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Final heatmap\", finalHm)\n",
    "cv2.imshow(\"Superimposed\", superimposed)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = drawKeypoints(images[1], keypoints[1])\n",
    "cv2.imshow(\"Image Keypoints\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = drawSkeleton(images[1], embedding[1])\n",
    "cv2.imshow(\"Image Keypoints\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
